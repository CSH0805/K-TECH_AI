import os
import torch
from ultralytics import YOLO
import shutil
import yaml
from pathlib import Path

def setup_advanced_training_environment():
    """ê³ ê¸‰ í›ˆë ¨ì„ ìœ„í•œ í™˜ê²½ ì„¤ì •"""
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    os.environ['TORCH_CPP_LOG_LEVEL'] = 'ERROR'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    
    # ê³ ê¸‰ YOLO ì„¤ì •
    os.environ['YOLO_VERBOSE'] = 'True'
    
    print("âœ… ê³ ê¸‰ í›ˆë ¨ í™˜ê²½ ì„¤ì • ì™„ë£Œ")

def validate_and_fix_yaml(yaml_path):
    """YAML íŒŒì¼ ê²€ì¦ ë° ê²½ë¡œ ìˆ˜ì •"""
    print("ğŸ” YAML íŒŒì¼ ê²€ì¦ ì¤‘...")
    
    try:
        with open(yaml_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        # ê²½ë¡œ ê²€ì¦ ë° ìˆ˜ì •
        paths_to_check = ['train', 'val', 'test']
        for path_key in paths_to_check:
            if path_key in data:
                path = Path(data[path_key])
                if not path.exists():
                    print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
                    # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½ ì‹œë„
                    relative_path = Path(yaml_path).parent / path.name
                    if relative_path.exists():
                        data[path_key] = str(relative_path)
                        print(f"âœ… ê²½ë¡œ ìˆ˜ì •: {data[path_key]}")
                    else:
                        print(f"âš ï¸  ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path_key}")
                else:
                    print(f"âœ… ê²½ë¡œ í™•ì¸: {path_key} -> {path}")
        
        # ìˆ˜ì •ëœ YAML ì €ì¥
        backup_path = yaml_path.replace('.yaml', '_backup.yaml')
        shutil.copy(yaml_path, backup_path)
        
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
        
        return data
        
    except Exception as e:
        print(f"âŒ YAML íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return None

def analyze_dataset(data_yaml):
    """ë°ì´í„°ì…‹ ë¶„ì„ ë° ê°œì„  ì œì•ˆ"""
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„ ì¤‘...")
    
    try:
        # YAML íŒŒì¼ ê²€ì¦ ë° ìˆ˜ì •
        data = validate_and_fix_yaml(data_yaml)
        if data is None:
            return 0, 0
        
        # ê° ê²½ë¡œë³„ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
        train_path = Path(data.get('train', 'train/images'))
        val_path = Path(data.get('val', 'valid/images'))
        test_path = Path(data.get('test', 'test/images')) if 'test' in data else None
        
        # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì
        img_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
        
        train_count = 0
        val_count = 0
        test_count = 0
        
        if train_path.exists():
            train_count = len([f for f in train_path.iterdir() if f.suffix.lower() in img_extensions])
        
        if val_path.exists():
            val_count = len([f for f in val_path.iterdir() if f.suffix.lower() in img_extensions])
            
        if test_path and test_path.exists():
            test_count = len([f for f in test_path.iterdir() if f.suffix.lower() in img_extensions])
        
        print(f"ğŸ“ í›ˆë ¨ ì´ë¯¸ì§€: {train_count}ê°œ")
        print(f"ğŸ“ ê²€ì¦ ì´ë¯¸ì§€: {val_count}ê°œ")
        if test_count > 0:
            print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_count}ê°œ")
        
        # í´ë˜ìŠ¤ ì •ë³´
        nc = data.get('nc', 0)
        names = data.get('names', [])
        print(f"ğŸ·ï¸  í´ë˜ìŠ¤ ìˆ˜: {nc}ê°œ")
        print(f"ğŸ·ï¸  í´ë˜ìŠ¤ ëª…: {names}")
        
        # ê°œì„  ì œì•ˆ
        if train_count < 500:
            print("âš ï¸  ê²½ê³ : í›ˆë ¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 500ê°œ ì´ìƒ ê¶Œì¥")
        
        if val_count < 100:
            print("âš ï¸  ê²½ê³ : ê²€ì¦ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 100ê°œ ì´ìƒ ê¶Œì¥")
            
        # ë¼ë²¨ íŒŒì¼ í™•ì¸
        train_label_path = train_path.parent / 'labels'
        val_label_path = val_path.parent / 'labels'
        
        if not train_label_path.exists():
            print("âŒ í›ˆë ¨ ë¼ë²¨ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        if not val_label_path.exists():
            print("âŒ ê²€ì¦ ë¼ë²¨ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        return train_count, val_count
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return 0, 0

def optimize_training_speed():
    """í›ˆë ¨ ì†ë„ ìµœì í™”"""
    print("âš¡ í›ˆë ¨ ì†ë„ ìµœì í™” ì¤‘...")
    
    # PyTorch ìµœì í™” ì„¤ì •
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    
    # ë©”ëª¨ë¦¬ ìµœì í™”
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        # RTX 4070 12GBë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ì„¤ì • (80% ì‚¬ìš©)
        torch.cuda.memory.set_per_process_memory_fraction(0.8)
    
    print("âœ… ì†ë„ ìµœì í™” ì™„ë£Œ")

def get_optimal_batch_size():
    """RTX 4070 12GBì— ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸°"""
    if not torch.cuda.is_available():
        return 4
    
    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
    print(f"ğŸ” GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
    
    # RTX 4070 12GB ê¸°ì¤€ ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
    batch_size = 8  # ë©”ëª¨ë¦¬ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
    
    print(f"ğŸ“Š ê¶Œì¥ ë°°ì¹˜ í¬ê¸°: {batch_size}")
    return batch_size

def train_fast_model():
    """ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•œ ìµœì í™”ëœ ì„¤ì •"""
    print("ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ í›ˆë ¨ ëª¨ë“œ ì‹œì‘...")
    
    setup_advanced_training_environment()
    optimize_training_speed()
    
    yaml_file = 'data.yaml'
    if not os.path.exists(yaml_file):
        raise FileNotFoundError(f"YAML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.abspath(yaml_file)}")

    # ë°ì´í„°ì…‹ ë¶„ì„
    train_count, val_count = analyze_dataset(yaml_file)
    
    if train_count == 0 or val_count == 0:
        print("âŒ ë°ì´í„°ì…‹ ê²½ë¡œ ë¬¸ì œë¡œ í›ˆë ¨ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False
    
    device = 0 if torch.cuda.is_available() else 'cpu'
    batch_size = get_optimal_batch_size()
    
    # ì†ë„ ìš°ì„  ì„¤ì •
    epochs = 50  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì€ ì—í¬í¬
    
    try:
        # ì‘ì€ ëª¨ë¸ ì‚¬ìš© (ì†ë„ ìš°ì„ )
        model = YOLO('yolo11n.pt')  # nano ëª¨ë¸ë¡œ ë¹ ë¥¸ í›ˆë ¨
        
        print(f"âš¡ ì„¤ì •: ë°°ì¹˜í¬ê¸°={batch_size}, ì—í¬í¬={epochs}, ëª¨ë¸=yolo11n")
        
        import time
        start_time = time.time()
        
        results = model.train(
            data=yaml_file,
            epochs=epochs,
            batch=batch_size,              # ë©”ëª¨ë¦¬ ì•ˆì „ ë°°ì¹˜ í¬ê¸°
            imgsz=640,                     
            project='.',
            name='fast_model',
        
            lr0=0.01,
            lrf=0.01,
            optimizer='SGD',
        
            augment=True,
            hsv_h=0.01,
            hsv_s=0.3,
            hsv_v=0.2,
            degrees=5.0,
            translate=0.1,
            scale=0.2,
            flipud=0.0,
            fliplr=0.3,
        
            dropout=0.0,
            weight_decay=0.0001,
            patience=30,

            workers=1,                     # ë©”ëª¨ë¦¬ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ 1ë¡œ ì„¤ì •
            cache=False,                   # ìºì‹œ ë¹„í™œì„±í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
            amp=True,
            device=0,
            verbose=True,
            save=True,
            plots=False,
            exist_ok=True,
        )
        
        end_time = time.time()
        total_time = end_time - start_time
        time_per_epoch = total_time / epochs
        
        print(f"â±ï¸  ì´ í›ˆë ¨ ì‹œê°„: {total_time/60:.1f}ë¶„")
        print(f"â±ï¸  ì—í¬í¬ë‹¹ ì‹œê°„: {time_per_epoch:.1f}ì´ˆ")
        
        # ëª¨ë¸ ì €ì¥
        best_model = './fast_model/weights/best.pt'
        if os.path.exists(best_model):
            shutil.copy(best_model, './Trash_model_fast.pt')
            print("ğŸ‰ ë¹ ë¥¸ í›ˆë ¨ ì™„ë£Œ!")
            return True
        
    except Exception as e:
        print(f"âŒ ë¹ ë¥¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        return False

def train_advanced_model():
    """ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ê³ ê¸‰ í›ˆë ¨ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    setup_advanced_training_environment()
    optimize_training_speed()
    
    yaml_file = 'data.yaml'
    if not os.path.exists(yaml_file):
        raise FileNotFoundError(f"YAML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.abspath(yaml_file)}")

    # ë°ì´í„°ì…‹ ë¶„ì„
    train_count, val_count = analyze_dataset(yaml_file)
    
    if train_count == 0 or val_count == 0:
        print("âŒ ë°ì´í„°ì…‹ ê²½ë¡œ ë¬¸ì œë¡œ í›ˆë ¨ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False
    
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        device = 0
        torch.cuda.set_device(0)
        print(f"ì‚¬ìš© GPU: {torch.cuda.get_device_name(0)}")
        torch.cuda.empty_cache()
    else:
        device = 'cpu'
        print("CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    # ê¸°ì¡´ ëª¨ë¸ ì •ë¦¬
    if os.path.exists('./advanced_model'):
        shutil.rmtree('./advanced_model')
    
    print("ğŸš€ ê³ ê¸‰ í›ˆë ¨ ì‹œì‘...")
    
    # RTX 4070ì— ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸°
    batch_size = 8  # ë©”ëª¨ë¦¬ ì•ˆì „ì„ ìœ„í•´ 8ë¡œ ì„¤ì •
    
    # ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¥¸ ë™ì  ì„¤ì •
    if train_count < 1000:
        epochs = 100  
        patience = 30
    else:
        epochs = 80
        patience = 20
    
    try:
        # YOLOv11s ëª¨ë¸ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
        model = YOLO('yolo11s.pt')  # m ëŒ€ì‹  s ëª¨ë¸ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        
        print(f"âš¡ ì„¤ì •: ë°°ì¹˜í¬ê¸°={batch_size}, ì—í¬í¬={epochs}, ëª¨ë¸=yolo11s")
        
        # ë©”ëª¨ë¦¬ ìµœì í™”ëœ í›ˆë ¨ íŒŒë¼ë¯¸í„°
        results = model.train(
            data=yaml_file,
            epochs=epochs,
            batch=batch_size,           # ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
            imgsz=640,              
            project='.',
            name='advanced_model',
            
            # í•™ìŠµë¥  ì„¤ì •
            lr0=0.01,               
            lrf=0.01,               
            
            # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
            optimizer='SGD',        
            
            # ë°ì´í„° ì¦ê°• ì„¤ì •
            augment=True,
            hsv_h=0.01,             
            hsv_s=0.3,              
            hsv_v=0.2,              
            degrees=5.0,            
            translate=0.1,          
            scale=0.2,              
            flipud=0.0,             
            fliplr=0.3,             
            
            # ì •ê·œí™” ì„¤ì •
            dropout=0.0,            
            weight_decay=0.0001,    
            
            # ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
            patience=patience,
            
            # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
            workers=1,                     # ì›Œì»¤ ìˆ˜ë¥¼ 1ë¡œ ì„¤ì • (ë©”ëª¨ë¦¬ ì—ëŸ¬ ë°©ì§€)
            device=device,
            verbose=True,
            save=True,
            plots=False,               
            exist_ok=True,
            
            # ìºì‹œ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
            cache=False,               # RAM ìºì‹œ ë¹„í™œì„±í™”
            
            # í˜¼í•© ì •ë°€ë„
            amp=True,                  
        )
        
        # ëª¨ë¸ ì €ì¥
        trained_model_path = './advanced_model/weights/best.pt'
        new_model_path = './Trash_model_advanced_yolo11s.pt'
        
        if os.path.exists(trained_model_path):
            shutil.copy(trained_model_path, new_model_path)
            print(f"ğŸ‰ ê³ ê¸‰ í›ˆë ¨ ì™„ë£Œ! ìƒˆë¡œìš´ ëª¨ë¸: {new_model_path}")
            
            # ëª¨ë¸ í¬ê¸° ì •ë³´
            model_size = os.path.getsize(new_model_path) / (1024 * 1024)
            print(f"ğŸ“ ëª¨ë¸ í¬ê¸°: {model_size:.1f}MB")
            
            # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
            if hasattr(results, 'results_dict'):
                print(f"ğŸ“ˆ ìµœê³  mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}")
                print(f"ğŸ“ˆ ìµœê³  mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}")
        else:
            print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        return True
        
    except Exception as e:
        print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

def train_high_performance_model():
    """ê³ ì„±ëŠ¥ í›ˆë ¨ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    print("ğŸ¯ ê³ ì„±ëŠ¥ í›ˆë ¨ ì‹œì‘...")
    
    setup_advanced_training_environment()
    
    yaml_file = 'data.yaml'
    train_count, val_count = analyze_dataset(yaml_file)
    
    if train_count == 0 or val_count == 0:
        return False
    
    device = 0 if torch.cuda.is_available() else 'cpu'
    
    try:
        model = YOLO('yolo11m.pt')  # m ëª¨ë¸ ì‚¬ìš©
        
        results = model.train(
            data=yaml_file,
            epochs=100,
            batch=6,                       # ë©”ëª¨ë¦¬ ì•ˆì „ì„ ìœ„í•´ ë” ì‘ì€ ë°°ì¹˜
            imgsz=640,
            project='.',
            name='high_performance_model',
            
            # ì›ë˜ ê³ ì„±ëŠ¥ ì„¤ì •
            lr0=0.001,
            optimizer='AdamW',
            
            # ê°•í•œ ë°ì´í„° ì¦ê°•
            augment=True,
            hsv_h=0.015,
            hsv_s=0.7,
            hsv_v=0.4,
            degrees=10.0,
            translate=0.2,
            scale=0.9,
            shear=2.0,
            perspective=0.0002,
            flipud=0.5,
            fliplr=0.5,
            mixup=0.1,
            copy_paste=0.1,
            
            dropout=0.1,
            weight_decay=0.0005,
            patience=50,
            workers=1,                     # ë©”ëª¨ë¦¬ ì•ˆì „
            device=device,
            verbose=True,
            save=True,
            plots=True,
            exist_ok=True,
            cache=False,                   # ìºì‹œ ë¹„í™œì„±í™”
        )
        
        best_model = './high_performance_model/weights/best.pt'
        if os.path.exists(best_model):
            shutil.copy(best_model, './Trash_model_high_performance.pt')
            return True
            
    except Exception as e:
        print(f"âŒ ê³ ì„±ëŠ¥ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        return False

def train_with_pretrained_model():
    """ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì „ì´ í•™ìŠµ"""
    print("ğŸ”„ ì „ì´ í•™ìŠµ ì‹œì‘...")
    
    # ê¸°ì¡´ì— í•™ìŠµí•œ ëª¨ë¸ì´ ìˆë‹¤ë©´ ê·¸ê²ƒë¶€í„° ì‹œì‘
    if os.path.exists('Trash_model_advanced_yolo11s.pt'):
        print("ğŸ“¦ ê¸°ì¡´ ê³ ê¸‰ ëª¨ë¸ì—ì„œ ì¶”ê°€ í•™ìŠµ ì‹œì‘...")
        model = YOLO('Trash_model_advanced_yolo11s.pt')
    elif os.path.exists('Trash_model.pt'):
        print("ğŸ“¦ ê¸°ì¡´ ëª¨ë¸ì—ì„œ ì¶”ê°€ í•™ìŠµ ì‹œì‘...")
        model = YOLO('Trash_model.pt')
    else:
        print("ğŸ“¦ YOLOv11s ëª¨ë¸ë¡œ ì‹œì‘...")
        model = YOLO('yolo11s.pt')  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ s ëª¨ë¸
    
    device = 0 if torch.cuda.is_available() else 'cpu'
    
    try:
        results = model.train(
            data='data.yaml',
            epochs=120,
            batch=8,                       # ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
            imgsz=640,
            project='.',
            name='transfer_model',
            
            # ì „ì´í•™ìŠµ ìµœì í™” ì„¤ì •
            lr0=0.0001,            
            warmup_epochs=5,       
            
            # ê°•í™”ëœ ì¦ê°•
            augment=True,
            mosaic=1.0,            
            mixup=0.15,            
            copy_paste=0.3,        
            
            # ì •ê·œí™”
            dropout=0.2,           
            
            patience=50,
            device=device,
            workers=1,                     # ë©”ëª¨ë¦¬ ì•ˆì „
            verbose=True,
            exist_ok=True,
            cache=False,                   # ìºì‹œ ë¹„í™œì„±í™”
        )
        
        # ê²°ê³¼ ì €ì¥
        best_model = './transfer_model/weights/best.pt'
        final_model = './Trash_model_transfer_yolo11s.pt'
        
        if os.path.exists(best_model):
            shutil.copy(best_model, final_model)
            print(f"ğŸ‰ ì „ì´í•™ìŠµ ì™„ë£Œ: {final_model}")
            return True
            
    except Exception as e:
        print(f"âŒ ì „ì´í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def ensemble_training():
    """ì•™ìƒë¸”ì„ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë¸ í›ˆë ¨ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    print("ğŸ­ ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨...")
    
    # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì‘ì€ ëª¨ë¸ë“¤ë§Œ ì‚¬ìš©
    models = ['yolo11n.pt', 'yolo11s.pt']
    trained_models = []
    
    device = 0 if torch.cuda.is_available() else 'cpu'
    
    for i, model_name in enumerate(models):
        print(f"ğŸ“¦ ëª¨ë¸ {i+1}/{len(models)} í›ˆë ¨ ì¤‘: {model_name}")
        
        model = YOLO(model_name)
        
        # ëª¨ë¸ í¬ê¸°ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¡°ì • (ë³´ìˆ˜ì )
        if 'n' in model_name:
            batch_size = 12
        else:  # s
            batch_size = 8
            
        if not torch.cuda.is_available():
            batch_size = max(2, batch_size // 4)
        
        try:
            results = model.train(
                data='data.yaml',
                epochs=80,
                batch=batch_size,
                imgsz=640,
                project='.',
                name=f'ensemble_model_{i}',
                
                # ê° ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥¸ ì¦ê°• ì„¤ì •
                augment=True,
                hsv_h=0.015 * (i + 1),
                degrees=5.0 * (i + 1),
                mixup=0.1 + 0.05 * i,
                
                patience=30,
                device=device,
                verbose=False,
                plots=False,
                exist_ok=True,
                workers=1,                 # ë©”ëª¨ë¦¬ ì•ˆì „
                cache=False,               # ìºì‹œ ë¹„í™œì„±í™”
            )
            
            # ëª¨ë¸ ì €ì¥
            best_path = f'./ensemble_model_{i}/weights/best.pt'
            if os.path.exists(best_path):
                final_path = f'./Trash_model_ensemble_{i}_yolo11.pt'
                shutil.copy(best_path, final_path)
                trained_models.append(final_path)
                print(f"âœ… ëª¨ë¸ {i+1} ì™„ë£Œ: {final_path}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ {i+1} í›ˆë ¨ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"ğŸŠ ì•™ìƒë¸” í›ˆë ¨ ì™„ë£Œ! {len(trained_models)}ê°œ ëª¨ë¸ ìƒì„±")
    return trained_models

def create_sample_yaml():
    """ìƒ˜í”Œ YAML íŒŒì¼ ìƒì„± (ê²½ë¡œê°€ ì˜ëª»ëœ ê²½ìš°)"""
    sample_yaml = """
# í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”
train: train/images
val: valid/images
test: test/images

nc: 5
names: ['Contamination', 'Glass', 'Metal', 'Paper', 'Plastic']

# Roboflow ì •ë³´ (ì„ íƒì‚¬í•­)
roboflow:
  workspace: mvidimension-measurement
  project: plastic-segregation-od
  version: 8
  license: CC BY 4.0
  url: https://universe.roboflow.com/mvidimension-measurement/plastic-segregation-od/dataset/8
"""
    
    with open('data_sample.yaml', 'w', encoding='utf-8') as f:
        f.write(sample_yaml.strip())
    
    print("ğŸ“„ ìƒ˜í”Œ YAML íŒŒì¼ ìƒì„±: data_sample.yaml")
    print("ğŸ’¡ ê²½ë¡œë¥¼ ìˆ˜ì •í•œ í›„ data.yamlë¡œ ì´ë¦„ì„ ë°”ê¿”ì£¼ì„¸ìš”")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ YOLOv11 ë©”ëª¨ë¦¬ ìµœì í™” í›ˆë ¨ (RTX 4070 12GB ìµœì í™”)")
    print("=" * 60)
    
    # YAML íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists('data.yaml'):
        print("âŒ data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        create_sample_yaml()
        return
    
    choice = input("""
ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ í›ˆë ¨í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
1. ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ í›ˆë ¨ (nano ëª¨ë¸, ë°°ì¹˜8, workers=1)
2. âš–ï¸  ê· í˜• í›ˆë ¨ (small ëª¨ë¸, ë°°ì¹˜8, workers=1)  
3. ğŸ¯ ê³ ì„±ëŠ¥ í›ˆë ¨ (medium ëª¨ë¸, ë°°ì¹˜6, workers=1)
4. ğŸ”„ ì „ì´í•™ìŠµ (ê¸°ì¡´ ëª¨ë¸ ê¸°ë°˜, ë°°ì¹˜8)
5. ğŸ­ ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨ (nano+small ëª¨ë¸)
6. ğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„ë§Œ ì‹¤í–‰
ì„ íƒ (1-6): """)
    
    if choice == '1':
        success = train_fast_model()
        if success:
            print("ğŸŠ ë¹ ë¥¸ í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif choice == '2':
        success = train_advanced_model()
        if success:
            print("ğŸŠ ê· í˜• í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif choice == '3':
        success = train_high_performance_model()
        if success:
            print("ğŸŠ ê³ ì„±ëŠ¥ í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif choice == '4':
        success = train_with_pretrained_model()
        if success:
            print("ğŸŠ ì „ì´í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif choice == '5':
        models = ensemble_training()
        if models:
            print(f"ğŸŠ ì•™ìƒë¸” í›ˆë ¨ ì™„ë£Œ! {len(models)}ê°œ ëª¨ë¸ ìƒì„±")
    elif choice == '6':
        analyze_dataset('data.yaml')
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

if __name__ == '__main__':
    main()